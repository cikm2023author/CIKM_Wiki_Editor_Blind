{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a10d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17094e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ee3b47c",
   "metadata": {},
   "source": [
    "## Process predicted post-edit text as outputted by t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_generated = \"data/new_pol/ampol_generator_output_test.txt\" # post-edit text predictions generated by generator model or e2e model\n",
    "line_id_file = 'data/new_pol/ampol_test_LIDS.txt'   # file to keep track of line_ids, output by Make_jsonl.ipynb\n",
    "outfile = 'data/new_pol/ampol_bleu_input.txt'  # temporary file used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newlines = []\n",
    "\n",
    "with open(t5_generated, 'r') as t5f:\n",
    "    for lidx, line in enumerate(t5f.readlines()):\n",
    "        line = line.strip()\n",
    "        newlines += [line]\n",
    "    lcount = lidx\n",
    "    \n",
    "with open(line_id_file, 'r') as lidf:\n",
    "    for lidx, line in enumerate(lidf.readlines()):\n",
    "        line = line.strip()\n",
    "        newlines[lidx] = newlines[lidx] + '\\t' + line + '\\n'\n",
    "    rcount = lidx\n",
    "    \n",
    "assert lcount == rcount\n",
    "\n",
    "with open(outfile, 'w') as outf:\n",
    "    outf.write('decoded_sentence\\tline_id\\n')\n",
    "    for line in newlines:\n",
    "        outf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6e48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2736f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7582631a",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = \"data/new_pol/ampol_test.tsv\"\n",
    "decoded_filename = 'data/new_pol/ampol_bleu_input.txt' # input is taken as output file from above\n",
    "outfilename = 'data/new_pol/ampol_bleu.txt' # output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d801264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# from https://stackoverflow.com/questions/70623867/can-every-solution-of-the-edit-distance-problem-be-shown-on-the-matrix-obtained\n",
    "def get_min_edit_count(text1, text2, get_edited_words=False):\n",
    "    \n",
    "    word1 = text1.strip().split()\n",
    "    word2 = text2.strip().split()\n",
    "    # we are doing lists of words rather than characters\n",
    "\n",
    "    word1 = ['BEGIN'] + word1     #\n",
    "    word2 = ['BEGIN'] + word2     # add a space before original words\n",
    "\n",
    "    len_w1 = len(word1)     #\n",
    "    len_w2 = len(word2)     # calculate the lengths of new words\n",
    "\n",
    "    old_edit_matrix = np.zeros((len_w2, len_w1), dtype = int)\n",
    "    edit_matrix = []\n",
    "    for i in range(len_w2):\n",
    "        edit_matrix.append([[0, []]] * len_w1)\n",
    "    #edit_matrix = np.array(edit_matrix)\n",
    "    \n",
    "    # create a matrix with all zeros\n",
    "    \n",
    "    edit_matrix[0][0] = [0, []]\n",
    "    \n",
    "    for col_idx in range(len_w1):\n",
    "        edit_matrix[0][col_idx] = [col_idx, [('DELETE', word1[j+1]) for j in range(col_idx)]]\n",
    "        \n",
    "    for row_idx in range(len_w2):\n",
    "        edit_matrix[row_idx][0] = [row_idx, [('INSERT', word2[i+1]) for i in range(row_idx)]]\n",
    "\n",
    "    old_edit_matrix[0, :] = range(len_w1)  \n",
    "    # assign numbers from 0 to len_w1 in the first row of the edit_matrix \n",
    "    old_edit_matrix[:, 0] = range(len_w2)\n",
    "    # assign numbers from 0 to len_w2 in the first column of the edit_matrix \n",
    "\n",
    "    for i in range(1, len_w2):\n",
    "        for j in range(1, len_w1):\n",
    "            #print j\n",
    "\n",
    "            temp1 = edit_matrix[i-1][j][0] + 1\n",
    "            temp2 = edit_matrix[i][j-1][0] + 1\n",
    "            # add 1 to edit_matrix[i-1][j] and edit_matrix[i][j-1]\n",
    "            \n",
    "            path1 = edit_matrix[i-1][j][1] + [('INSERT', word2[i])]\n",
    "            path2 = edit_matrix[i][j-1][1] + [('DELETE', word1[j])]\n",
    "\n",
    "            \n",
    "            temp3 = edit_matrix[i-1][j-1][0]\n",
    "            if word1[j] != word2[i]:\n",
    "                temp3 += 1\n",
    "                action = ('REPLACE', (word1[j], word2[i]))\n",
    "            else:\n",
    "                action = ('SKIP', word1[j])\n",
    "            path3 = edit_matrix[i-1][j-1][1] + [action]\n",
    "            # if last characters are same don't add 1 to edit_matrix[i-1][j-1].\n",
    "            # no need to replace\n",
    "\n",
    "            edit_count = min(temp1, temp2, temp3)\n",
    "            # find min between three numbers\n",
    "\n",
    "            path_options = []\n",
    "            for temp, path in [(temp1,path1), (temp2,path2), (temp3,path3)]:\n",
    "                if temp == edit_count:\n",
    "                    path_options += [path]\n",
    "\n",
    "            edit_matrix[i][j] = [edit_count, random.choice(path_options)]\n",
    "    \n",
    "    if get_edited_words:\n",
    "        return edit_matrix[-1][-1]\n",
    "    return edit_matrix[-1][-1][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs = pd.read_csv(input_filename, sep='\\t')\n",
    "df_decoded = pd.read_csv(decoded_filename, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce2f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20754fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs = df_inputs.set_index('line_id')\n",
    "df_decoded = df_decoded.set_index('line_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144799ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_decoded.join(df_inputs)\n",
    "df = df_decoded.join(df_inputs,lsuffix='b_')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores = np.zeros(df.shape[0])\n",
    "df['Score'] = scores\n",
    "\n",
    "with open(outfilename,'w') as outfile:\n",
    "    outfile.write('line_id\\tarticle_title\\tuser\\trevision_number\\tdecoded\\trevision_text\\tpre-edit\\tbleu_score\\tpre_len\\tpred_len\\tpost_len\\n')\n",
    "    for index, row in df.iterrows():\n",
    "        candidate = str(row['decoded_sentence']).strip().split()\n",
    "        reference = str(row['revision text']).strip().split()\n",
    "        \n",
    "        pre_edit = row['parent text'].strip().split()\n",
    "\n",
    "        try:\n",
    "            score = sentence_bleu([reference], candidate, (0.25, 0.25, 0.25, 0.25))\n",
    "        except:\n",
    "            score = np.nan\n",
    "            \n",
    "        outfile.write(str(index)+'\\t'\n",
    "                      +row['article_title']+'\\t'\n",
    "                      +str(row['user'])+'\\t'\n",
    "                      +str(row['revision_number'])+'\\t'\n",
    "                      +str(row['decoded_sentence'])+'\\t'\n",
    "                      +str(row['revision text'])+'\\t'\n",
    "                      +str(row['parent text'])+'\\t'\n",
    "                      +str(score)+'\\t'\n",
    "                      +str(len(pre_edit))+'\\t'\n",
    "                      +str(len(candidate))+'\\t'\n",
    "                      +str(len(reference))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average bleu scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ce2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "infilename = outfilename # read file we just outputted as dataframe\n",
    "df_bleus = pd.read_csv(infilename, sep='\\t')\n",
    "df_bleus = df_bleus.set_index('line_id')\n",
    "df_bleus = df_bleus.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e68dfe",
   "metadata": {},
   "source": [
    "### Note that bleu_score is 4-gram bleu across all words, is NOT the metric from the paper, and is NOT an appropriate metric for our dataset. See further below for the metric used in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3025e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is bleu score is not a good metric \n",
    "df_bleus['bleu_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "beb_bleu_weights=(1.0, 0.0, 0.0, 0.0)\n",
    "def compute_CUBE(in_text, out_text, pred_text):\n",
    "    trueED = get_min_edit_count(in_text, out_text, get_edited_words=True)\n",
    "    predED = get_min_edit_count(in_text, pred_text, get_edited_words=True)\n",
    "    \n",
    "    trueWordsAdded = [word for (edit_type, word) in trueED[1] if edit_type in ['INSERT']]\n",
    "    predWordsAdded = [word for (edit_type, word) in predED[1] if edit_type in ['INSERT']]\n",
    "    \n",
    "    trueWordsRemoved = [word for (edit_type, word) in trueED[1] if edit_type in ['DELETE']]\n",
    "    predWordsRemoved = [word for (edit_type, word) in predED[1] if edit_type in ['DELETE']]\n",
    "\n",
    "    trueWordsAdded += [word[1] for (edit_type, word) in trueED[1] if edit_type in ['REPLACE']]\n",
    "    predWordsAdded += [word[1] for (edit_type, word) in predED[1] if edit_type in ['REPLACE']]\n",
    "    trueWordsRemoved += [word[0] for (edit_type, word) in trueED[1] if edit_type in ['REPLACE']]\n",
    "    predWordsRemoved += [word[0] for (edit_type, word) in predED[1] if edit_type in ['REPLACE']]\n",
    "    \n",
    "    addscore = sentence_bleu([trueWordsAdded], predWordsAdded, weights=beb_bleu_weights, auto_reweigh=True)\n",
    "    remscore = sentence_bleu([trueWordsRemoved], predWordsRemoved, weights=beb_bleu_weights, auto_reweigh=True)\n",
    "    score = (addscore * len(trueWordsAdded) + remscore * len(trueWordsRemoved))/float(len(trueWordsAdded) + len(trueWordsRemoved))\n",
    "    return score, addscore, remscore, len(trueWordsAdded), len(trueWordsRemoved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f171656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bleus['CUBE'] = [0.0]*len(df_bleus.index)\n",
    "df_bleus['CUBE_ins'] = [0.0]*len(df_bleus.index)\n",
    "df_bleus['CUBE_del'] = [0.0]*len(df_bleus.index)\n",
    "df_bleus['words_added'] = [0.0]*len(df_bleus.index)\n",
    "df_bleus['words_removed'] = [0.0]*len(df_bleus.index)\n",
    "counter = 0\n",
    "for ridx, row in df_bleus.iterrows():\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(str(counter) + ' of ' + str(len(df_bleus.index)))\n",
    "    edit_bleu = compute_CUBE(row['pre-edit'], row['revision_text'], row['decoded'])\n",
    "    \n",
    "    df_bleus.at[ridx, 'CUBE'] = better_edit_bleu[0]\n",
    "    df_bleus.at[ridx, 'CUBE_ins'] = better_edit_bleu[1]\n",
    "    df_bleus.at[ridx, 'CUBE_del'] = better_edit_bleu[2]\n",
    "    \n",
    "    df_bleus.at[ridx, 'words_added'] = better_edit_bleu[3]\n",
    "    df_bleus.at[ridx, 'words_removed'] = better_edit_bleu[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001fba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_bleus['CUBE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f29758",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bleus['CUBE_ins'][df_bleus['words_added'] > 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa33dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bleus['CUBE_del'][df_bleus['words_removed'] > 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "newbleuout = infilename\n",
    "df_bleus.to_csv(newbleuout, sep='\\t') # update same tsv file with CUBE metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
